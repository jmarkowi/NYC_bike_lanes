{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into `train`/`test` folders\n",
    "\n",
    "Using split-folders package: https://pypi.org/project/split-folders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T17:10:54.161570Z",
     "start_time": "2021-10-14T17:10:54.142884Z"
    }
   },
   "outputs": [],
   "source": [
    "import splitfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From instructions on package's website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:42:30.666085Z",
     "start_time": "2021-10-13T14:42:30.663975Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Split with a ratio.\n",
    "# # To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "# splitfolders.ratio(\"raw_images\", \n",
    "#                    output=\"input_images\", \n",
    "#                    seed=42, \n",
    "#                    ratio=(.8, .2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tues 10/12, 1:30pm:**\n",
    "\n",
    "It worked! The package created copies of all my files, sorted into `train` and `val` folders, each containing the originally named folders/split. \n",
    "\n",
    "For now I'm going to delete these, then re-run this code after I have added to the dataset a little today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T14:43:35.890704Z",
     "start_time": "2021-10-13T14:43:19.988663Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1461 files [00:15, 91.90 files/s] \n"
     ]
    }
   ],
   "source": [
    "# Split with a fixed number of items.\n",
    "# To only split into training and validation set, use a single number to `fixed`, i.e., `10`.\n",
    "splitfolders.fixed(\"raw_images\", \n",
    "                   output=\"input_images\", \n",
    "                   seed=42, \n",
    "                   fixed=(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wed 10/13, 10:30am:**\n",
    "\n",
    "Performed operation on full dataset after cropping images.\n",
    "\n",
    "Decided to set aside 100 images of each class as holdout/test set and will use `validation_split` parameter in Keras's `ImageDataGenerator` to split the training set during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2:30pm:**\n",
    "\n",
    "Had to repeat this process after re-orienting all images with `exif_transpose` (see EDA notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T18:36:00.309284Z",
     "start_time": "2021-10-13T18:36:00.137457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete metadata files created by Mac OS\n",
    "!find . -name \".DS_Store\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-13T18:36:10.807155Z",
     "start_time": "2021-10-13T18:36:01.910381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1461 files [00:08, 164.31 files/s]\n"
     ]
    }
   ],
   "source": [
    "# Split with a fixed number of items.\n",
    "# To only split into training and validation set, use a single number to `fixed`, i.e., `10`.\n",
    "splitfolders.fixed(\"processed_images\", \n",
    "                   output=\"input_images\", \n",
    "                   seed=42, \n",
    "                   fixed=(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thu Oct 14, 12pm:**\n",
    "\n",
    "At data meeting with Max, he suggested reducing the number in the holdout set to 100 total (not 100 per class, which tbh I thought I was doing). Maximize training set since it's already so small!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-14T17:12:32.371412Z",
     "start_time": "2021-10-14T17:12:18.723115Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1461 files [00:13, 108.61 files/s]\n"
     ]
    }
   ],
   "source": [
    "# Delete metadata files created by Mac OS\n",
    "!find . -name \".DS_Store\" -delete\n",
    "\n",
    "# Split with a fixed number of items.\n",
    "# To only split into training and validation set, use a single number to `fixed`, i.e., `10`.\n",
    "splitfolders.fixed(\"other_images/processed_images\", \n",
    "                   output=\"input_images\", \n",
    "                   seed=42, \n",
    "                   fixed=(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

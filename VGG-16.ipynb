{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using VGG-16 as a base model for transfer learning\n",
    "\n",
    "Now that I've trained a simple model using VGG-16 as a base, using only one Dense layer before output, I'd like to iterate on it to see how I can improve it. I'll be doing the same for InceptionV3 and comparing the two in order to make a final decision for my best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T16:35:55.422745Z",
     "start_time": "2021-10-19T16:35:48.387157Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from pickle import dump\n",
    "\n",
    "from functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T17:47:18.358002Z",
     "start_time": "2021-10-19T17:47:18.036084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image folder for training\n",
    "train_dir = 'input_images/full_combined'\n",
    "val_dir = 'input_images/validation'\n",
    "\n",
    "# Delete metadata files created by Mac OS\n",
    "!find . -name \".DS_Store\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T17:47:24.712862Z",
     "start_time": "2021-10-19T17:47:24.564578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1619 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make generators -- NOW USING SEPARATE VALIDATION SET/FOLDER (see split-folders.ipynb for details)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   horizontal_flip=True,\n",
    "                                   rotation_range=20, \n",
    "                                   brightness_range=[0.5, 1.5], \n",
    "                                   zoom_range=.2)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(train_dir, class_mode='binary')\n",
    "val_gen = val_datagen.flow_from_directory(val_dir, class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate base model\n",
    "\n",
    "I'll use the VGG-16 model without its original Dense layers for feature extraction. I'll then add my own Dense layers and sigmoid activation output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T17:47:30.220176Z",
     "start_time": "2021-10-19T17:47:29.660983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get base model\n",
    "vgg_base_model = VGG16(weights='imagenet', \n",
    "                       include_top=False,\n",
    "                       input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze layers\n",
    "for layer in vgg_base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Check architecture\n",
    "vgg_base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterations\n",
    "\n",
    "Before, I simply added one Dense(512) layer on top of the base architecture. The original architecture of VGG-16 has 3 fully dense layers with 4096 nodes, generating predictions for 1000 classes w/Softmax activation. I'll be stepping that way down, plus only generating binary predictions with sigmoid activation.\n",
    "\n",
    "I'll use `train_gen` and `val_gen` as defined above, but also bump up the number of epochs to 30 since it seemed like there was still room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top with 2 Dense(512) layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T17:55:31.311510Z",
     "start_time": "2021-10-19T17:55:31.098812Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "vgg_1 = models.Sequential()\n",
    "\n",
    "# Add base model\n",
    "vgg_1.add(vgg_base_model)\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "vgg_1.add(Flatten())\n",
    "\n",
    "# Add 2 fully connected layers with 512 hidden units and ReLU activation\n",
    "vgg_1.add(Dense(512, activation='relu'))\n",
    "vgg_1.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "vgg_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "vgg_1.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.507623Z",
     "start_time": "2021-10-19T17:55:31.970140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "51/51 [==============================] - 329s 6s/step - loss: 1.0882 - acc: 0.7023 - recall: 0.7133 - precision: 0.7081 - val_loss: 0.3027 - val_acc: 0.8700 - val_recall: 0.7400 - val_precision: 1.0000\n",
      "Epoch 2/30\n",
      "51/51 [==============================] - 319s 6s/step - loss: 0.3570 - acc: 0.8382 - recall: 0.8193 - precision: 0.8586 - val_loss: 0.2465 - val_acc: 0.8900 - val_recall: 0.9000 - val_precision: 0.8824\n",
      "Epoch 3/30\n",
      "51/51 [==============================] - 313s 6s/step - loss: 0.3487 - acc: 0.8474 - recall: 0.8325 - precision: 0.8648 - val_loss: 0.2148 - val_acc: 0.9100 - val_recall: 0.9000 - val_precision: 0.9184\n",
      "Epoch 4/30\n",
      "51/51 [==============================] - 326s 6s/step - loss: 0.2818 - acc: 0.8752 - recall: 0.8687 - precision: 0.8857 - val_loss: 0.2031 - val_acc: 0.9200 - val_recall: 0.8600 - val_precision: 0.9773\n",
      "Epoch 5/30\n",
      "51/51 [==============================] - 326s 6s/step - loss: 0.2739 - acc: 0.8845 - recall: 0.8687 - precision: 0.9024 - val_loss: 0.2144 - val_acc: 0.9100 - val_recall: 0.8400 - val_precision: 0.9767\n",
      "Epoch 6/30\n",
      "51/51 [==============================] - 335s 7s/step - loss: 0.2784 - acc: 0.8740 - recall: 0.8687 - precision: 0.8836 - val_loss: 0.2486 - val_acc: 0.8800 - val_recall: 0.7600 - val_precision: 1.0000\n",
      "Epoch 7/30\n",
      "51/51 [==============================] - 468s 9s/step - loss: 0.2302 - acc: 0.9036 - recall: 0.8892 - precision: 0.9202 - val_loss: 0.1981 - val_acc: 0.9300 - val_recall: 0.9600 - val_precision: 0.9057\n",
      "Epoch 8/30\n",
      "51/51 [==============================] - 440s 9s/step - loss: 0.2383 - acc: 0.8962 - recall: 0.8952 - precision: 0.9017 - val_loss: 0.1659 - val_acc: 0.9400 - val_recall: 0.9000 - val_precision: 0.9783\n",
      "Epoch 9/30\n",
      "51/51 [==============================] - 435s 9s/step - loss: 0.2081 - acc: 0.9111 - recall: 0.8964 - precision: 0.9277 - val_loss: 0.1919 - val_acc: 0.9500 - val_recall: 0.9200 - val_precision: 0.9787\n",
      "Epoch 10/30\n",
      "51/51 [==============================] - 434s 9s/step - loss: 0.2395 - acc: 0.8975 - recall: 0.8867 - precision: 0.9109 - val_loss: 0.1832 - val_acc: 0.9500 - val_recall: 0.9000 - val_precision: 1.0000\n",
      "Epoch 11/30\n",
      "51/51 [==============================] - 435s 9s/step - loss: 0.2207 - acc: 0.9104 - recall: 0.8964 - precision: 0.9265 - val_loss: 0.2362 - val_acc: 0.9000 - val_recall: 0.9400 - val_precision: 0.8704\n",
      "Epoch 12/30\n",
      "51/51 [==============================] - 436s 9s/step - loss: 0.2112 - acc: 0.9117 - recall: 0.9096 - precision: 0.9174 - val_loss: 0.1793 - val_acc: 0.9400 - val_recall: 0.9200 - val_precision: 0.9583\n",
      "Epoch 13/30\n",
      "51/51 [==============================] - 461s 9s/step - loss: 0.2050 - acc: 0.9222 - recall: 0.9060 - precision: 0.9400 - val_loss: 0.2091 - val_acc: 0.9200 - val_recall: 0.8800 - val_precision: 0.9565\n",
      "Epoch 14/30\n",
      "51/51 [==============================] - 470s 9s/step - loss: 0.1951 - acc: 0.9148 - recall: 0.9108 - precision: 0.9220 - val_loss: 0.3207 - val_acc: 0.8600 - val_recall: 0.7400 - val_precision: 0.9737\n",
      "Epoch 15/30\n",
      "51/51 [==============================] - 477s 9s/step - loss: 0.1702 - acc: 0.9358 - recall: 0.9241 - precision: 0.9493 - val_loss: 0.2265 - val_acc: 0.9300 - val_recall: 0.9000 - val_precision: 0.9574\n",
      "Epoch 16/30\n",
      "51/51 [==============================] - 430s 8s/step - loss: 0.2029 - acc: 0.9191 - recall: 0.9145 - precision: 0.9267 - val_loss: 0.2073 - val_acc: 0.9300 - val_recall: 0.9400 - val_precision: 0.9216\n",
      "Epoch 17/30\n",
      "51/51 [==============================] - 432s 8s/step - loss: 0.1545 - acc: 0.9351 - recall: 0.9301 - precision: 0.9426 - val_loss: 0.1736 - val_acc: 0.9400 - val_recall: 0.9000 - val_precision: 0.9783\n",
      "Epoch 18/30\n",
      "51/51 [==============================] - 468s 9s/step - loss: 0.1454 - acc: 0.9432 - recall: 0.9398 - precision: 0.9489 - val_loss: 0.3202 - val_acc: 0.8900 - val_recall: 0.9400 - val_precision: 0.8545\n",
      "Epoch 19/30\n",
      "51/51 [==============================] - 479s 9s/step - loss: 0.1683 - acc: 0.9284 - recall: 0.9193 - precision: 0.9397 - val_loss: 0.1843 - val_acc: 0.9500 - val_recall: 0.9400 - val_precision: 0.9592\n",
      "Epoch 20/30\n",
      "51/51 [==============================] - 535s 10s/step - loss: 0.1433 - acc: 0.9432 - recall: 0.9410 - precision: 0.9478 - val_loss: 0.1935 - val_acc: 0.9500 - val_recall: 0.9400 - val_precision: 0.9592\n",
      "Epoch 21/30\n",
      "51/51 [==============================] - 475s 9s/step - loss: 0.1677 - acc: 0.9271 - recall: 0.9277 - precision: 0.9300 - val_loss: 0.3066 - val_acc: 0.8800 - val_recall: 0.7600 - val_precision: 1.0000\n",
      "Epoch 22/30\n",
      "51/51 [==============================] - 483s 9s/step - loss: 0.1395 - acc: 0.9438 - recall: 0.9386 - precision: 0.9512 - val_loss: 0.2228 - val_acc: 0.9300 - val_recall: 0.9400 - val_precision: 0.9216\n",
      "Epoch 23/30\n",
      "51/51 [==============================] - 477s 9s/step - loss: 0.1506 - acc: 0.9308 - recall: 0.9289 - precision: 0.9357 - val_loss: 0.1692 - val_acc: 0.9500 - val_recall: 0.9400 - val_precision: 0.9592\n",
      "Epoch 24/30\n",
      "51/51 [==============================] - 458s 9s/step - loss: 0.0978 - acc: 0.9636 - recall: 0.9554 - precision: 0.9730 - val_loss: 0.1967 - val_acc: 0.9200 - val_recall: 0.9600 - val_precision: 0.8889\n",
      "Epoch 25/30\n",
      "51/51 [==============================] - 470s 9s/step - loss: 0.1490 - acc: 0.9456 - recall: 0.9361 - precision: 0.9569 - val_loss: 0.1840 - val_acc: 0.9400 - val_recall: 0.9400 - val_precision: 0.9400\n",
      "Epoch 26/30\n",
      "51/51 [==============================] - 533s 10s/step - loss: 0.1091 - acc: 0.9568 - recall: 0.9578 - precision: 0.9578 - val_loss: 0.3926 - val_acc: 0.8700 - val_recall: 0.7600 - val_precision: 0.9744\n",
      "Epoch 27/30\n",
      "51/51 [==============================] - 462s 9s/step - loss: 0.1406 - acc: 0.9450 - recall: 0.9398 - precision: 0.9524 - val_loss: 0.2051 - val_acc: 0.9300 - val_recall: 0.8800 - val_precision: 0.9778\n",
      "Epoch 28/30\n",
      "51/51 [==============================] - 482s 9s/step - loss: 0.0811 - acc: 0.9673 - recall: 0.9627 - precision: 0.9732 - val_loss: 0.2862 - val_acc: 0.9300 - val_recall: 0.9200 - val_precision: 0.9388\n",
      "Epoch 29/30\n",
      "17/51 [=========>....................] - ETA: 4:54 - loss: 0.0931 - acc: 0.9651 - recall: 0.9642 - precision: 0.9676"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " FileNotFoundError: [Errno 2] No such file or directory: 'input_images/full_combined/open_bike_lane/IMG_1030.jpeg'\nTraceback (most recent call last):\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 814, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 940, in generator_fn\n    yield x[i]\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'input_images/full_combined/open_bike_lane/IMG_1030.jpeg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2252]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e1d60d282901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m vgg_1_history = vgg_1.fit(train_gen,\n\u001b[0m\u001b[1;32m      3\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                           validation_data=val_gen)\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  FileNotFoundError: [Errno 2] No such file or directory: 'input_images/full_combined/open_bike_lane/IMG_1030.jpeg'\nTraceback (most recent call last):\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 814, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 940, in generator_fn\n    yield x[i]\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py\", line 227, in _get_batches_of_transformed_samples\n    img = load_img(filepaths[j],\n\n  File \"/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'input_images/full_combined/open_bike_lane/IMG_1030.jpeg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2252]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "vgg_1_history = vgg_1.fit(train_gen,\n",
    "                          epochs=30,\n",
    "                          validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.552819Z",
     "start_time": "2021-10-19T17:59:06.049Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_1.save('models/vgg_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.554270Z",
     "start_time": "2021-10-19T18:00:16.942Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_results(vgg_1_history, vgg_1, train_gen, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.555515Z",
     "start_time": "2021-10-19T18:00:42.085Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(vgg_1_history.history, open('models/vgg_1_history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Dense layers and aggressive (0.5) Dropout to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.556733Z",
     "start_time": "2021-10-19T18:10:15.130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "vgg_2 = models.Sequential()\n",
    "\n",
    "# Add base model\n",
    "vgg_2.add(vgg_base_model)\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "vgg_2.add(Flatten())\n",
    "\n",
    "# Add 2 fully connected layers with 512 hidden units and ReLU activation,\n",
    "# plus Dropout layers\n",
    "vgg_2.add(Dense(512, activation='relu'))\n",
    "vgg_2.add(Dropout(0.5))\n",
    "vgg_2.add(Dense(512, activation='relu'))\n",
    "vgg_2.add(Dropout(0.5))\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "vgg_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "vgg_2.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.560716Z",
     "start_time": "2021-10-19T18:11:11.599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "vgg_2_history = vgg_2.fit(train_gen,\n",
    "                          epochs=30,\n",
    "                          validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.562228Z",
     "start_time": "2021-10-19T18:11:28.022Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_2.save('models/vgg_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.563760Z",
     "start_time": "2021-10-19T18:11:36.614Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_results(vgg_2_history, vgg_2, train_gen, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.571445Z",
     "start_time": "2021-10-19T18:11:48.285Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(vgg_2_history.history, open('models/vgg_2_history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Dense layers with decreasing number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.572882Z",
     "start_time": "2021-10-19T18:13:33.906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "vgg_3 = models.Sequential()\n",
    "\n",
    "# Add base model\n",
    "vgg_3.add(vgg_base_model)\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "vgg_3.add(Flatten())\n",
    "\n",
    "# Add 2 fully connected layers with 512 hidden units and ReLU activation,\n",
    "# plus Dropout layers\n",
    "vgg_3.add(Dense(512, activation='relu'))\n",
    "vgg_3.add(Dense(128, activation='relu'))\n",
    "vgg_3.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "vgg_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile\n",
    "vgg_3.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['acc', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.574379Z",
     "start_time": "2021-10-19T18:13:46.625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "vgg_3_history = vgg_3.fit(train_gen,\n",
    "                          epochs=30,\n",
    "                          validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.575596Z",
     "start_time": "2021-10-19T18:13:54.186Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg_3.save('models/vgg_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.577015Z",
     "start_time": "2021-10-19T18:14:04.096Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_results(vgg_3_history, vgg_3, train_gen, val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T21:27:04.578583Z",
     "start_time": "2021-10-19T18:14:12.880Z"
    }
   },
   "outputs": [],
   "source": [
    "dump(vgg_3_history.history, open('models/vgg_3_history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

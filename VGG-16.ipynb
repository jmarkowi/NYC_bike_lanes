{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using VGG-16 as a base model for transfer learning\n",
    "\n",
    "Now that I've trained a simple model using VGG-16 as a base, using only one Dense layer before output, I'd like to iterate on it to see how I can improve it. I'll be doing the same for InceptionV3 and comparing the two in order to make a final decision for my best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T16:35:55.422745Z",
     "start_time": "2021-10-19T16:35:48.387157Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from pickle import dump\n",
    "\n",
    "from functions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T16:35:55.856687Z",
     "start_time": "2021-10-19T16:35:55.424914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Image folder for training\n",
    "train_dir = 'input_images/full_combined'\n",
    "\n",
    "# Delete metadata files created by Mac OS\n",
    "!find . -name \".DS_Store\" -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-19T16:36:20.012283Z",
     "start_time": "2021-10-19T16:36:19.825459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1548 images belonging to 2 classes.\n",
      "Found 171 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make generators with image aug as before\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                    validation_split=0.1,\n",
    "                                    horizontal_flip=True,\n",
    "                                    rotation_range=20, \n",
    "                                    brightness_range=[0.5, 1.5], \n",
    "                                    zoom_range=.2)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(train_dir, subset='training', class_mode='binary')\n",
    "val_gen = train_datagen.flow_from_directory(train_dir, subset='validation', class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate base model\n",
    "\n",
    "I'll use the VGG-16 model without its original Dense layers for feature extraction. I'll then add my own Dense layers and sigmoid activation output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get base model\n",
    "vgg_base_model = VGG16(weights='imagenet', \n",
    "                       include_top=False,\n",
    "                       input_shape=(256, 256, 3))\n",
    "\n",
    "# Freeze layers\n",
    "for layer in vgg_base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Check architecture\n",
    "vgg_base_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
